{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-05T14:58:13.710053Z",
     "start_time": "2025-07-05T14:58:10.824424Z"
    }
   },
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "import optax\n",
    "from itertools import combinations\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from concrete_CCQC_digits import concrete_CCQC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.random.seed(42)\n",
    "# Load the digits dataset with features (X_digits) and labels (y_digits)\n",
    "X_digits, y_digits = load_digits(return_X_y=True)\n",
    "\n",
    "# Create a boolean mask to filter out only the samples where the label is 2 or 6\n",
    "filter_mask = np.isin(y_digits, [2, 6])\n",
    "\n",
    "# Apply the filter mask to the features and labels to keep only the selected digits\n",
    "X_digits = X_digits[filter_mask]\n",
    "y_digits = y_digits[filter_mask]\n",
    "\n",
    "# Split the filtered dataset into training and testing sets with 10% of data reserved for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_digits, y_digits, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# Normalize the pixel values in the training and testing data\n",
    "# Convert each image from a 1D array to an 8x8 2D array, normalize pixel values, and scale them\n",
    "X_train = np.array([thing.reshape([8, 8]) / 16 * 2 * np.pi for thing in X_train])\n",
    "X_test = np.array([thing.reshape([8, 8]) / 16 * 2 * np.pi for thing in X_test])\n",
    "\n",
    "# Adjust the labels to be centered around 0 and scaled to be in the range -1 to 1\n",
    "# The original labels (2 and 6) are mapped to -1 and 1 respectively\n",
    "y_train = (y_train - 4) / 2\n",
    "y_test = (y_test - 4) / 2\n",
    "\n",
    "\n",
    "# TO PLOT NUMBERS:\n",
    "# fig, axes = plt.subplots(nrows=2, ncols=3, layout=\"constrained\")\n",
    "# for i in range(2):\n",
    "#     for j in range(3):\n",
    "#       axes[i][j].matshow(X_train[2*(2*j+i)])\n",
    "#       axes[i][j].axis('off')\n",
    "# \n",
    "# fig.subplots_adjust(hspace=0.0)\n",
    "# fig.tight_layout()\n",
    "# plt.show()"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-05T14:58:13.719908Z",
     "start_time": "2025-07-05T14:58:13.714007Z"
    }
   },
   "source": [
    "# def feature_map(features):\n",
    "#     # Apply Hadamard gates to all qubits to create an equal superposition state\n",
    "#     for i in range(len(features[0])):\n",
    "#         qml.Hadamard(i)\n",
    "# \n",
    "#     # Apply angle embeddings based on the feature values\n",
    "#     for i in range(len(features)):\n",
    "#         # For odd-indexed features, use Z-rotation in the angle embedding\n",
    "#         if i % 2:\n",
    "#             qml.AngleEmbedding(features=features[i], wires=range(8), rotation=\"Z\")\n",
    "#         # For even-indexed features, use X-rotation in the angle embedding\n",
    "#         else:\n",
    "#             qml.AngleEmbedding(features=features[i], wires=range(8), rotation=\"X\")\n",
    "# \n",
    "# # Define the ansatz (quantum circuit ansatz) for parameterized quantum operations\n",
    "# def ansatz(params):\n",
    "#     # Apply RY rotations with the first set of parameters\n",
    "#     for i in range(8):\n",
    "#         qml.RY(params[i], wires=i)\n",
    "# \n",
    "#     # Apply CNOT gates with adjacent qubits (cyclically connected) to create entanglement\n",
    "#     for i in range(8):\n",
    "#         qml.CNOT(wires=[(i - 1) % 8, (i) % 8])\n",
    "# \n",
    "#     # Apply RY rotations with the second set of parameters\n",
    "#     for i in range(8):\n",
    "#         qml.RY(params[i + 8], wires=i)\n",
    "# \n",
    "#     # Apply CNOT gates with qubits in reverse order (cyclically connected)\n",
    "#     # to create additional entanglement\n",
    "#     for i in range(8):\n",
    "#         qml.CNOT(wires=[(8 - 2 - i) % 8, (8 - i - 1) % 8])"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational approach\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-05T14:58:54.590261Z",
     "start_time": "2025-07-05T14:58:13.722721Z"
    }
   },
   "source": [
    "# dev = qml.device(\"default.qubit\", wires=8)\n",
    "\n",
    "# @qml.qnode(dev)\n",
    "# def circuit(params, features):\n",
    "#     feature_map(features)\n",
    "#     ansatz(params)\n",
    "#     return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "# def variational_classifier(weights, bias, x):\n",
    "#     return circuit(weights, x) + bias\n",
    "\n",
    "\n",
    "def square_loss(labels, predictions):\n",
    "    return np.mean((labels - qml.math.stack(predictions)) ** 2)\n",
    "\n",
    "\n",
    "def accuracy(labels, predictions):\n",
    "    acc = sum([np.sign(l) == np.sign(p) for l, p in zip(labels, predictions)])\n",
    "    acc = acc / len(labels)\n",
    "    return acc\n",
    "\n",
    "\n",
    "def cost(params, X, Y):\n",
    "    predictions = []\n",
    "    for x in X:\n",
    "        vqc = concrete_CCQC(data=x, weights=params[\"weights\"], bias=params[\"bias\"])\n",
    "        predictions.append(vqc())\n",
    "    return square_loss(Y, predictions)\n",
    "\n",
    "\n",
    "def acc(params, X, Y):\n",
    "    predictions = []\n",
    "    for x in X:\n",
    "        vqc = concrete_CCQC(data=x, weights=params[\"weights\"], bias=params[\"bias\"])\n",
    "        predictions.append(vqc())\n",
    "    # predictions = [variational_classifier(params[\"weights\"], params[\"bias\"], x) for x in X]\n",
    "    return accuracy(Y, predictions)\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "weights = 0.01 * np.random.randn(16)\n",
    "bias = jnp.array(0.0)\n",
    "params = {\"weights\": weights, \"bias\": bias}\n",
    "opt = optax.adam(0.05)\n",
    "batch_size = 7\n",
    "num_batch = X_train.shape[0] // batch_size\n",
    "opt_state = opt.init(params)\n",
    "X_batched = X_train.reshape([-1, batch_size, 8, 8])\n",
    "y_batched = y_train.reshape([-1, batch_size])\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def update_step_jit(i, args):\n",
    "    params, opt_state, data, targets, batch_no = args\n",
    "    _data = data[batch_no % num_batch]\n",
    "    _targets = targets[batch_no % num_batch]\n",
    "    _, grads = jax.value_and_grad(cost)(params, _data, _targets)\n",
    "    updates, opt_state = opt.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return (params, opt_state, data, targets, batch_no + 1)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def optimization_jit(params, data, targets):\n",
    "    opt_state = opt.init(params)\n",
    "    args = (params, opt_state, data, targets, 0)\n",
    "    (params, opt_state, _, _, _) = jax.lax.fori_loop(0, 200, update_step_jit, args)\n",
    "    return params\n",
    "\n",
    "\n",
    "params = optimization_jit(params, X_batched, y_batched)\n",
    "var_train_acc = acc(params, X_train, y_train)\n",
    "var_test_acc = acc(params, X_test, y_test)\n",
    "\n",
    "print(\"Training accuracy: \", var_train_acc)\n",
    "print(\"Testing accuracy: \", var_test_acc)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-07-05 16:58:13,771:jax._src.xla_bridge:967: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.7484472049689441\n",
      "Testing accuracy:  0.6944444444444444\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T14:58:54.612670Z",
     "start_time": "2025-07-05T14:58:54.594526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(params)\n",
    "# save the parameters to a file\n",
    "np.savez(\"variational_params.npz\", weights=params[\"weights\"], bias=params[\"bias\"])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bias': Array(-0.2207043, dtype=float32), 'weights': Array([-0.08074556,  0.72621405,  0.33415344, -0.27907464,  0.5078599 ,\n",
      "        0.03533619, -2.9683018 , -1.3685347 , -1.7326092 , -0.7025906 ,\n",
      "       -1.1073234 ,  0.37724453,  0.26312652,  0.3450798 , -0.40563133,\n",
      "       -0.46257365], dtype=float32)}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T14:58:54.634001Z",
     "start_time": "2025-07-05T14:58:54.616318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "read_params = np.load(\"variational_params.npz\")\n",
    "weights = read_params[\"weights\"]\n",
    "bias = read_params[\"bias\"]\n",
    "print(\"Read weights: \", weights)\n",
    "print(\"Read bias: \", bias)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read weights:  [-0.08074556  0.72621405  0.33415344 -0.27907464  0.5078599   0.03533619\n",
      " -2.9683018  -1.3685347  -1.7326092  -0.7025906  -1.1073234   0.37724453\n",
      "  0.26312652  0.3450798  -0.40563133 -0.46257365]\n",
      "Read bias:  -0.2207043\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
