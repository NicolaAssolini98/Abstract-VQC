{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T14:03:49.334503Z",
     "start_time": "2025-07-06T14:03:49.326286Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'jax' has no attribute 'version' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m get_ipython().run_line_magic(\u001b[33m'\u001b[39m\u001b[33mmatplotlib\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33minline\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpennylane\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqml\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpennylane\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m numpy \u001b[38;5;28;01mas\u001b[39;00m np\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjax\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/pennylane/__init__.py:21\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03mThis is the top level module from which all basic functions and classes of\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[33;03mPennyLane can be directly imported.\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpennylane\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mboolean_fn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BooleanFn\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpennylane\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnumpy\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpennylane\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mqueuing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QueuingManager, apply\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpennylane\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompiler\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/pennylane/numpy/__init__.py:87\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mautograd\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m numpy \u001b[38;5;28;01mas\u001b[39;00m _np\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mautograd\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwrapper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m extract_tensors, tensor_wrapper, wrap_arrays\n\u001b[32m     89\u001b[39m wrap_arrays(_np.\u001b[34m__dict__\u001b[39m, \u001b[38;5;28mglobals\u001b[39m())\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# Delete the unwrapped fft, linalg, random modules\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[38;5;66;03m# so that we can re-import our wrapped versions.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/pennylane/numpy/wrapper.py:23\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mabc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequence\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mautograd\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m numpy \u001b[38;5;28;01mas\u001b[39;00m _np\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract_tensors\u001b[39m(x):\n\u001b[32m     27\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Iterate through an iterable, and extract any PennyLane\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[33;03m    tensors that appear.\u001b[39;00m\n\u001b[32m     29\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     43\u001b[39m \u001b[33;03m    [tensor(0.1, requires_grad=True)]\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/pennylane/numpy/tensor.py:25\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mautograd\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnumpy_vspaces\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArrayVSpace, ComplexArrayVSpace\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mautograd\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtracer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Box\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpennylane\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moperation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Operator\n\u001b[32m     27\u001b[39m \u001b[34m__doc__\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mNumPy with automatic differentiation support, provided by Autograd and PennyLane.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Hotfix since _np.asarray doesn't have a gradient rule defined.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/pennylane/operation.py:235\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpennylane\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqml\u001b[39;00m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpennylane\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcapture\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ABCCaptureMeta, create_operator_primitive\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpennylane\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmath\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m expand_matrix\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpennylane\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mqueuing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QueuingManager\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpennylane\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorLike\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/pennylane/math/__init__.py:37\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mautoray\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mar\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mis_independent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_independent\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmatrix_manipulation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m expand_matrix, expand_vector, reduce_matrices, get_batch_size\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmulti_dispatch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     39\u001b[39m     add,\n\u001b[32m     40\u001b[39m     array,\n\u001b[32m   (...)\u001b[39m\u001b[32m     65\u001b[39m     where,\n\u001b[32m     66\u001b[39m )\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     68\u001b[39m     cov_matrix,\n\u001b[32m     69\u001b[39m     dm_from_state_vector,\n\u001b[32m   (...)\u001b[39m\u001b[32m     84\u001b[39m     trace_distance,\n\u001b[32m     85\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/pennylane/math/matrix_manipulation.py:25\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, eye, kron\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpennylane\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqml\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpennylane\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwires\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Wires\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexpand_matrix\u001b[39m(mat, wires, wire_order=\u001b[38;5;28;01mNone\u001b[39;00m, sparse_format=\u001b[33m\"\u001b[39m\u001b[33mcsr\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     29\u001b[39m     \u001b[38;5;66;03m# pylint: disable=too-many-branches\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Re-express a matrix acting on a subspace defined by a set of wire labels\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[33;03m    according to a global wire order.\u001b[39;00m\n\u001b[32m     32\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    103\u001b[39m \n\u001b[32m    104\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/pennylane/wires.py:29\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpennylane\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpytrees\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m register_pytree\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m util.find_spec(\u001b[33m\"\u001b[39m\u001b[33mjax\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     jax = \u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mjax\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m     jax_available = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/importlib/__init__.py:90\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     88\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     89\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/jax/__init__.py:39\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m _cloud_tpu_init\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Confusingly there are two things named \"config\": the module and the class.\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# We want the exported object to be the class, so we first import the module\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# to make sure a later import doesn't overwrite the class.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjax\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config \u001b[38;5;28;01mas\u001b[39;00m _config_module\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m _config_module\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Force early import, allowing use of `jax.core` after importing `jax`.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/jax/config.py:15\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2018 The JAX Authors.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjax\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_src\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config \u001b[38;5;28;01mas\u001b[39;00m _deprecated_config  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Deprecations\u001b[39;00m\n\u001b[32m     19\u001b[39m _deprecations = {\n\u001b[32m     20\u001b[39m     \u001b[38;5;66;03m# Added October 27, 2023\u001b[39;00m\n\u001b[32m     21\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m\"\u001b[39m: (\n\u001b[32m     22\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAccessing jax.config via the jax.config submodule is deprecated.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     23\u001b[39m         _deprecated_config),\n\u001b[32m     24\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/jax/_src/config.py:28\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Generic, NamedTuple, NoReturn, TypeVar\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjax\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_src\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m lib\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjax\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_src\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m jax_jit\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjax\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_src\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m transfer_guard_lib\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/jax/_src/lib/__init__.py:75\u001b[39m\n\u001b[32m     70\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m _jaxlib_version\n\u001b[32m     73\u001b[39m version_str = jaxlib.version.__version__\n\u001b[32m     74\u001b[39m version = check_jaxlib_version(\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m   jax_version=\u001b[43mjax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mversion\u001b[49m.__version__,\n\u001b[32m     76\u001b[39m   jaxlib_version=jaxlib.version.__version__,\n\u001b[32m     77\u001b[39m   minimum_jaxlib_version=jax.version._minimum_jaxlib_version)\n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# Before importing any C compiled modules from jaxlib, first import the CPU\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# feature guard module to verify that jaxlib was compiled in a way that only\u001b[39;00m\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# uses instructions that are present on this machine.\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjaxlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcpu_feature_guard\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcpu_feature_guard\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: partially initialized module 'jax' has no attribute 'version' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "import optax\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from concrete_CCQC_digits import concrete_CCQC\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from skimage.transform import resize\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "def replace_values(arr, old_value, new_value):\n",
    "    return np.where(arr == old_value, new_value, arr)\n",
    "\n",
    "def resize_image(images, new_size=(4, 4)):\n",
    "    \"\"\"Resize a 2D image to a new size.\"\"\"\n",
    "    return np.array([resize(img, new_size, anti_aliasing=True) for img in images])\n",
    "\n",
    "def square_loss(labels, predictions):\n",
    "    return np.mean((labels - qml.math.stack(predictions)) ** 2)\n",
    "\n",
    "\n",
    "def accuracy(labels, predictions):\n",
    "    acc = sum([np.sign(l) == np.sign(p) for l, p in zip(labels, predictions)])\n",
    "    acc = acc / len(labels)\n",
    "    return acc\n",
    "\n",
    "\n",
    "def cost(params, X, Y):\n",
    "    predictions = []\n",
    "    for x in X:\n",
    "        vqc = concrete_CCQC(data=x, weights=params[\"weights\"], bias=params[\"bias\"])\n",
    "        predictions.append(vqc())\n",
    "    return square_loss(Y, predictions)\n",
    "\n",
    "\n",
    "def acc(params, X, Y):\n",
    "    predictions = []\n",
    "    for x in X:\n",
    "        vqc = concrete_CCQC(data=x, weights=params[\"weights\"], bias=params[\"bias\"])\n",
    "        predictions.append(vqc())\n",
    "    # predictions = [variational_classifier(params[\"weights\"], params[\"bias\"], x) for x in X]\n",
    "    return accuracy(Y, predictions)\n",
    "\n",
    "@jax.jit\n",
    "def update_step_jit(i, args):\n",
    "    params, opt_state, data, targets, batch_no = args\n",
    "    _data = data[batch_no % num_batch]\n",
    "    _targets = targets[batch_no % num_batch]\n",
    "    _, grads = jax.value_and_grad(cost)(params, _data, _targets)\n",
    "    updates, opt_state = opt.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return (params, opt_state, data, targets, batch_no + 1)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def optimization_jit(params, data, targets):\n",
    "    opt_state = opt.init(params)\n",
    "    args = (params, opt_state, data, targets, 0)\n",
    "    (params, opt_state, _, _, _) = jax.lax.fori_loop(0, 200, update_step_jit, args)\n",
    "    return params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = 4 # 2,3,4 better choices\n",
    "class_0 = 2\n",
    "class_1 = 6\n",
    "\n",
    "# Load the digits dataset with features (X_digits) and labels (y_digits)\n",
    "X_digits, y_digits = load_digits(return_X_y=True)\n",
    "\n",
    "# Create a boolean mask to filter out only the samples where the label is 2 or 6\n",
    "filter_mask = np.isin(y_digits, [class_0, class_1])\n",
    "\n",
    "# Apply the filter mask to the features and labels to keep only the selected digits\n",
    "X_digits = X_digits[filter_mask]\n",
    "y_digits = y_digits[filter_mask]\n",
    "\n",
    "# Split the filtered dataset into training and testing sets with 10% of data reserved for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_digits, y_digits, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# Normalize the pixel values in the training and testing data\n",
    "# Convert each image from a 1D array to an 8x8 2D array, normalize pixel values, and scale them\n",
    "X_train = np.array([thing.reshape([8, 8]) / 16 * 2 * np.pi for thing in X_train])\n",
    "X_test = np.array([thing.reshape([8, 8]) / 16 * 2 * np.pi for thing in X_test])\n",
    "\n",
    "# Adjust the labels to be centered around 0 and scaled to be in the range -1 to 1\n",
    "# The original labels (2 and 6) are mapped to -1 and 1 respectively\n",
    "y_train = replace_values(y_train, class_0, -1)\n",
    "y_train = replace_values(y_train, class_1, 1)\n",
    "y_test = replace_values(y_test, class_0, -1)\n",
    "y_test = replace_values(y_test, class_1, 1)\n",
    "\n",
    "# Resize the images to 4x4\n",
    "X_train = resize_image(X_train, new_size=(num_qubits, num_qubits))\n",
    "X_test = resize_image(X_test, new_size=(num_qubits, num_qubits))\n",
    "\n",
    "# # TO PLOT NUMBERS:\n",
    "# fig, axes = plt.subplots(nrows=2, ncols=3, layout=\"constrained\")\n",
    "# for i in range(2):\n",
    "#     for j in range(3):\n",
    "#       axes[i][j].matshow(X_train[2*(2*j+i)])\n",
    "#       axes[i][j].axis('off')\n",
    "# \n",
    "# fig.subplots_adjust(hspace=0.0)\n",
    "# fig.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "weights = 0.01 * np.random.randn(num_qubits*2)\n",
    "bias = jnp.array(0.0)\n",
    "params = {\"weights\": weights, \"bias\": bias}\n",
    "opt = optax.adam(0.05)\n",
    "batch_size = 7\n",
    "num_batch = X_train.shape[0] // batch_size\n",
    "opt_state = opt.init(params)\n",
    "X_batched = X_train.reshape([-1, batch_size, num_qubits, num_qubits])\n",
    "y_batched = y_train.reshape([-1, batch_size])\n",
    "\n",
    "print(X_batched.shape)\n",
    "# Variational approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vqc = concrete_VQC(data=np.ones(4), weights=np.ones(4))\n",
    "qml.draw_mpl(vqc.circuit,decimals=2)()\n",
    "plt.savefig(\"CCQC_iris.pdf\", format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = optimization_jit(params, X_batched, y_batched)\n",
    "var_train_acc = acc(params, X_train, y_train)\n",
    "var_test_acc = acc(params, X_test, y_test)\n",
    "\n",
    "print(\"Training accuracy: \", var_train_acc)\n",
    "print(\"Testing accuracy: \", var_test_acc)\n",
    "print(params)\n",
    "# save the parameters to a file\n",
    "np.savez(f\"variational_params_{num_qubits}.npz\", weights=params[\"weights\"], bias=params[\"bias\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T14:06:04.148622Z",
     "start_time": "2025-07-06T14:06:04.139267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read weights:  [-0.66718936 -0.9948772  -1.3700426  -0.0658858  -0.00887135 -0.0803882\n",
      "  0.10717992 -0.18775432]\n",
      "Read bias:  -0.4678205\n"
     ]
    }
   ],
   "source": [
    "read_params = np.load(f\"variational_params_{num_qubits}.npz\")\n",
    "weights = read_params[\"weights\"]\n",
    "bias = read_params[\"bias\"]\n",
    "print(\"Read weights: \", weights)\n",
    "print(\"Read bias: \", bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results training with different resizing\n",
    "\n",
    "4,4: \n",
    "\n",
    "Train:    0.8354037267080745\n",
    "\n",
    "Testing:  0.7777777777777778\n",
    "\n",
    "----------\n",
    "3, 3:\n",
    "\n",
    "Training accuracy:  0.8850931677018633\n",
    "\n",
    "Testing accuracy:  0.8333333333333334\n",
    "\n",
    "----------\n",
    "2, 2:\n",
    "\n",
    "Training accuracy:  0.8105590062111802\n",
    "\n",
    "Testing accuracy:  0.8888888888888888"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
